{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import functools\n",
    "\n",
    "os.chdir('..')\n",
    "sys.path.append('..')\n",
    "from data import dataset\n",
    "from models import burn_in_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE_SPEC = (\n",
    "    tf.TensorSpec([None, 14, 20], tf.float32),\n",
    "    tf.TensorSpec([None, 19], tf.float32),\n",
    "    tf.TensorSpec([None, 3], tf.int32)\n",
    ")\n",
    "\n",
    "class SimpleSequentialLSTM_SavedModel(burn_in_lstm.SimpleSequentialLSTM):\n",
    "    def __init__(self):\n",
    "        super(SimpleSequentialLSTM_SavedModel, self).__init__()\n",
    "    \n",
    "    @tf.function(input_signature=[INPUT_SHAPE_SPEC])\n",
    "    def call(self, input_ops):\n",
    "        input_seq, input_basic_num, input_basic_cat = input_ops\n",
    "\n",
    "        # processing sequential features\n",
    "        seq_list = tf.unstack(input_seq, axis=1)\n",
    "        seq_embedding = tf.stack([self.shared_dense(seq) for seq in seq_list], axis=1)\n",
    "        lstm_output, state_h, state_c = self.lstm(seq_embedding)\n",
    "        \n",
    "        # processing basic features\n",
    "        industry, area, codenum = tf.unstack(input_basic_cat, axis=-1)\n",
    "        industry_embedded = self.industry_embedding(industry)\n",
    "        area_embedded = self.area_embedding(area)\n",
    "        codenum_embedded = self.code_embedding(codenum)\n",
    "\n",
    "        basic_features = tf.concat([\n",
    "            input_basic_num, industry_embedded, area_embedded, codenum_embedded\n",
    "        ], axis=-1)\n",
    "        basic_embedding = self.basic_dense(basic_features)\n",
    "\n",
    "        # processing global features\n",
    "        global_features = tf.concat([state_h, basic_embedding], axis=-1)\n",
    "        logits = self.global_dense(global_features)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "ds_train, ds_test = dataset.build_tfrecord_dataset('/home/yuki/Documents/ymx/stock_research/data/records', 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method SimpleSequentialLSTM_SavedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fda7240b400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SimpleSequentialLSTM_SavedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fda7240b400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method SimpleSequentialLSTM_SavedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fda7240b400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SimpleSequentialLSTM_SavedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fda7240b400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fda726506a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fda726506a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fda726506a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fda726506a8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method SimpleSequentialLSTM_SavedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fda7240b400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SimpleSequentialLSTM_SavedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fda7240b400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method SimpleSequentialLSTM_SavedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fda7240b400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SimpleSequentialLSTM_SavedModel.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fda7240b400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      " [*] Loaded pretrained model basic_lstm.v2.01.hdf5\n"
     ]
    }
   ],
   "source": [
    "def load_model():\n",
    "#     model = burn_in_lstm.SimpleSequentialLSTM()\n",
    "#     model = burn_in_lstm.BurnInStateLSTM()\n",
    "    model = SimpleSequentialLSTM_SavedModel()\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    adam = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "    metrics = [\n",
    "        tf.keras.metrics.BinaryAccuracy(name='acc'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "    model.compile(loss=loss, optimizer=adam, metrics=metrics)\n",
    "    #model.build(input_shape=[(None, 14, 20), (None, 19), (None, 3)])\n",
    "    xs, ys = next(iter(ds_train))\n",
    "    model.call(xs)\n",
    "\n",
    "    model_basedir = '/home/yuki/Documents/ymx/stock_research/train'\n",
    "    if 'basic_lstm.v2.01.hdf5' in os.listdir(model_basedir):\n",
    "        model.load_weights(os.path.join(model_basedir, 'basic_lstm.v2.01.hdf5'))\n",
    "        print(' [*] Loaded pretrained model basic_lstm.v2.01.hdf5')\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute KNN similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "stock_basics = pd.read_csv('./data/stock_basics.csv')\n",
    "\n",
    "def get_codenum_representation():\n",
    "    value_set = list(set(stock_basics['codenum'].values.tolist()))\n",
    "    value_set = list(map(lambda x: str(x).zfill(6), value_set))\n",
    "    value_hash = dict(zip(value_set, list(range(len(value_set)))))\n",
    "    return value_hash\n",
    "\n",
    "stock_code_hash = get_codenum_representation()\n",
    "stock_code_hash_reversed = dict(zip(stock_code_hash.values(), stock_code_hash.keys()))\n",
    "# pprint.pprint(stock_code_hash)\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>>>>>>>>> iter=3801\n",
      "['国海证券', '东北证券', '永太科技', '国光电器', '吉药控股', '安阳钢铁', '鹏欣资源']\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "def from_code_to_name(codestr):\n",
    "    codenum = stock_code_hash_reversed[int(codestr)]\n",
    "    dfline = stock_basics[stock_basics['codenum'] == int(codenum)]\n",
    "    assert len(dfline) == 1, f'codestr={codestr} len(dfline)={len(dfline)}'\n",
    "    return dfline['name'].values[0]\n",
    "\n",
    "def get_knn_mapping(k=7):\n",
    "    heapdict = {key: [] for key in stock_code_hash.keys()}\n",
    "    niter = 0\n",
    "    for x, xcode in stock_code_hash.items():\n",
    "        ycodes = list(stock_code_hash.values()).copy()\n",
    "        ycodes.remove(stock_code_hash[x])\n",
    "        xcodes_arr = np.array([xcode] * len(ycodes), dtype=np.int32)\n",
    "        ycodes_arr = np.array(ycodes, dtype=np.int32)\n",
    "        simarray = model.stock_cosine_similarity(xcodes_arr, ycodes_arr)\n",
    "        topk = tf.argsort(simarray, direction='DESCENDING')[: k]\n",
    "        topk = topk.numpy().tolist()\n",
    "        for elem in topk:\n",
    "            heapdict[x].append(from_code_to_name(ycodes[elem]))\n",
    "        if niter % 100 == 1:\n",
    "            print('\\r', f'>>>>>>>>>> iter={niter}', end='')\n",
    "        niter += 1\n",
    "    print('')\n",
    "    return heapdict\n",
    "\n",
    "\n",
    "stock_knn_mapping = get_knn_mapping()\n",
    "print(stock_knn_mapping['600000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model as pb\n",
    "\n",
    "Note: 本方法首先有些要求需要满足:\n",
    "- 可以拿的到模型的网络结构定义源码\n",
    "- 网络结构里面的所有操作都是通过tf.keras完成的, 不能出现类似tf.nn 的tensorflow自己的操作符\n",
    "- tf2.0下保存的模型是.h5格式的,并且仅保存了weights, 即通过model.save_weights保存的模型.\n",
    "\n",
    "-------------------\n",
    "\n",
    "Refer to: https://blog.csdn.net/Murdock_C/java/article/details/103204875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fda72943ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fda72943ae8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fda72943ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function canonicalize_signatures.<locals>.signature_wrapper at 0x7fda72943ae8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fda728d1d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fda728d1d08>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fda728d1d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fda728d1d08>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.SimpleSequentialLSTM_SavedModel object at 0x7fda72a04240>, because its inputs are not defined.\n",
      "WARNING:tensorflow:Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7fda726506a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7fda726506a8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7fda726506a8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function _wrap_call_and_conditional_losses.<locals>.call_and_return_conditional_losses at 0x7fda726506a8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Skipping full serialization of object <tensorflow.python.keras.layers.recurrent.RNN object at 0x7fda729131d0>, because an error occurred while tracing layer functions. Error message: in converted code:\n",
      "    relative to /home/yuki/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras:\n",
      "\n",
      "    saving/saved_model.py:1143 call_and_return_conditional_losses\n",
      "        return layer_call(inputs, training=training), layer.get_losses_for(inputs)\n",
      "    layers/recurrent.py:743 call\n",
      "        zero_output_for_mask=self.zero_output_for_mask)\n",
      "    backend.py:3806 rnn\n",
      "        input_time_zero, tuple(initial_states) + tuple(constants))\n",
      "    layers/recurrent.py:728 step\n",
      "        output, new_states = self.cell.call(inputs, states, **kwargs)\n",
      "\n",
      "    TypeError: wrapped_call() takes 1 positional argument but 2 were given\n",
      "\n",
      "INFO:tensorflow:Assets written to: /tmp/fucking-awesome.pb/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, '/tmp/fucking-awesome.pb', signatures={'predict': model.call})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_checkpoint_dependencies',\n",
       " '_deferred_dependencies',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_handle_deferred_dependencies',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_self_name_based_restores',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_setattr_tracking',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " 'area_embedding',\n",
       " 'basic_dense',\n",
       " 'code_embedding',\n",
       " 'global_dense',\n",
       " 'industry_embedding',\n",
       " 'keras_api',\n",
       " 'layer-0',\n",
       " 'layer-1',\n",
       " 'layer-2',\n",
       " 'layer-3',\n",
       " 'layer-4',\n",
       " 'layer-5',\n",
       " 'layer-6',\n",
       " 'layer_with_weights-0',\n",
       " 'layer_with_weights-1',\n",
       " 'layer_with_weights-2',\n",
       " 'layer_with_weights-3',\n",
       " 'layer_with_weights-4',\n",
       " 'layer_with_weights-5',\n",
       " 'layer_with_weights-6',\n",
       " 'lstm',\n",
       " 'optimizer',\n",
       " 'shared_dense',\n",
       " 'signatures',\n",
       " 'tensorflow_git_version',\n",
       " 'tensorflow_version']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrecord_ds, _ = dataset.build_tfrecord_dataset('/home/yuki/Documents/ymx/stock_research/data/records', 1, 1)\n",
    "model_tmp = tf.saved_model.load('/tmp/fucking-awesome.pb/')\n",
    "\n",
    "xs, ys = next(iter(tfrecord_ds))\n",
    "dir(model_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tmp.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
